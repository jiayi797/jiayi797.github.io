<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
<!-- Referrer Policy调整致不蒜子单页面统计出错:https://senorui.top/posts/c33f.html -->
<meta name="referrer" content="no-referrer-when-downgrade">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiayi797.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本节是吴恩达老师在deepLearning.ai第二周课程的笔记。 本节以逻辑回归的梯度下降法为例，讲了我们究竟如何使用梯度下降法。 LR的梯度下降 在LR中，我们想要得到z&#x3D;wx+b，并且这个z在样本上，损失函数L(a,y)最小。那么，我们可以不断地改变w和b，找到一个合适的w和b，达到我们上述的目的。  如何改变w和b，能更快地得到最优的w和b呢？那么我们就要使用梯度下降法。  上">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习算法-引言-LR的梯度下降法">
<meta property="og:url" content="http://jiayi797.github.io/about/2017/09/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%BC%95%E8%A8%80-LR%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/index.html">
<meta property="og:site_name" content="甲乙小朋友的房子">
<meta property="og:description" content="本节是吴恩达老师在deepLearning.ai第二周课程的笔记。 本节以逻辑回归的梯度下降法为例，讲了我们究竟如何使用梯度下降法。 LR的梯度下降 在LR中，我们想要得到z&#x3D;wx+b，并且这个z在样本上，损失函数L(a,y)最小。那么，我们可以不断地改变w和b，找到一个合适的w和b，达到我们上述的目的。  如何改变w和b，能更快地得到最优的w和b呢？那么我们就要使用梯度下降法。  上">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2017/09/04/59acd4eac78da.png">
<meta property="og:image" content="https://i.loli.net/2017/09/04/59acd39e1a9ea.png">
<meta property="article:published_time" content="2017-09-04T04:13:01.000Z">
<meta property="article:modified_time" content="2018-12-17T07:42:03.000Z">
<meta property="article:author" content="jiayi797">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2017/09/04/59acd4eac78da.png">

<link rel="canonical" href="http://jiayi797.github.io/about/2017/09/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%BC%95%E8%A8%80-LR%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>深度学习算法-引言-LR的梯度下降法 | 甲乙小朋友的房子</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">甲乙小朋友的房子</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">甲乙小朋友很笨，但甲乙小朋友不会放弃</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://jiayi797.github.io/about/2017/09/04/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%BC%95%E8%A8%80-LR%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jiayi797">
      <meta itemprop="description" content=".">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="甲乙小朋友的房子">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习算法-引言-LR的梯度下降法
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-09-04 12:13:01" itemprop="dateCreated datePublished" datetime="2017-09-04T12:13:01+08:00">2017-09-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2018-12-17 15:42:03" itemprop="dateModified" datetime="2018-12-17T15:42:03+08:00">2018-12-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">深度学习算法</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">神经网络</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本节是吴恩达老师在deepLearning.ai第二周课程的笔记。</p>
<p>本节以逻辑回归的梯度下降法为例，讲了我们究竟如何使用梯度下降法。</p>
<h1 id="lr的梯度下降">LR的梯度下降</h1>
<p>在LR中，我们想要得到z=wx+b，并且这个z在样本上，损失函数L(a,y)最小。那么，我们可以不断地改变w和b，找到一个合适的w和b，达到我们上述的目的。</p>
<p><img src="https://i.loli.net/2017/09/04/59acd4eac78da.png" /></p>
<p>如何改变w和b，能更快地得到最优的w和b呢？那么我们就要使用梯度下降法。 <img src="https://i.loli.net/2017/09/04/59acd39e1a9ea.png" /></p>
<p>上图中，从左到右的计算过程就是前向传播法。</p>
<p>一般来说，我们都用后向传播法来计算这个过程：</p>
<p>在单个样本中， 想要计算<span class="math inline">\(L(a,y)\)</span>的导数: 1. 先向前一步，计算损失函数<span class="math inline">\(L(a,y)\)</span>关于<span class="math inline">\(a\)</span>的导数<span class="math inline">\(da = \frac{dL(a,y)}{da} = -\frac{y}{a} + \frac{1-y}{1-a}\)</span>。 2. 再向前一步，计算<span class="math inline">\(dz = \frac{dL}{dz} = a - y\)</span> 3. 再向前一步，计算<span class="math inline">\(dw = \frac{dL}{dw} = ...=x(a-y), db = ...=a-y\)</span> 4. 用 $ w = w - dw,b = b - db$</p>
<p>在m个训练集中， <span class="math inline">\(J(w,b) = \frac{1}{m} \sum{_i^m L(a^{(i)},y^{(i)})}\)</span> 那么： <span class="math inline">\(\frac{d(J(w,b))}{w1} = \frac{1}{m}\sum_i^m\frac{d(L(w^{(i)},y^{(i)}))}{w_i}\)</span></p>
<p>也就是说，m个训练样本的损失函数的导数 = 每个训练样本损失函数导数的均值</p>
<p>伪代码：</p>
<pre><code>J = 0; dw1 = 0; dw2 = 0 ; db = 0;
for i = 1 to m :
    z = w1x1[i] + w2x2[i] + b ;
    y = sigmod(z) ;
    a = get(i) ;
    J += ylog(a) + (1-y)log(1-a);
    dz = a - y; # 先算dz
    dw1+= x1dz; # 后算dw,db
    dw2 += x2dz;
    db+= dz;
J/= m;
dw1 /= m;
dw2 /= m;
db /= m; </code></pre>
<p>此时就已经得到了全部样本的dw1,dw2,db,J</p>
<p>然后应用梯度下降：</p>
<pre><code>w1 = w1 - sdw1
w2 = w2 - sdw2
b = b - sb</code></pre>
<p>其中，s是步长。</p>
<h1 id="向量化">向量化</h1>
<p>一般来说，for循环是很不好的。可以使用向量化来摆脱for循环，加速运算。接下来我们来讲一讲向量化。</p>
<p>一般来说，如果我们想计算<span class="math inline">\(z = w^T x + b\)</span>,其中，w和x都是一个n维的列向量。在非向量化实现中，我们会用：</p>
<pre><code>z = 0;
for i in range(n):
    z += w[i]*x[i];
z += b ;</code></pre>
<p>在向量化（例如numpy中），我们用：</p>
<pre><code>z = np.dot(w,x) + b</code></pre>
<p>向量运算非常快（主要原因是并行运算）。因此我们尽量将loop运算转换为向量运算。</p>
<h1 id="向量化的lr">向量化的LR</h1>
<p>x是m维向量</p>
<pre><code>import numpy as np
J = 0; dw1 = 0; dw2 = 0 ; db = 0;
z = np.dot(w.T,x) + b; # m维列向量
y = sigmod(z) ;# m维列向量
a = label;# m维列向量
J = np.dot(y.T,log(a)) + np.dot((1-y).T,log(1-a));
J/= m;
dz = a - y; # 先算dz
dw1 = np.dot(x1.T,dz) /m ; # 后算dw,db
dw2 = np.dot(x2.T,dz) /m ;
db= np.sum(dz) /m ;</code></pre>
<p>然后应用梯度下降：</p>
<pre><code>w1 = w1 - sdw1
w2 = w2 - sdw2
b = b - sb</code></pre>
<h1 id="总结">总结</h1>
<p>这一节主要讲了我们如何将梯度下降法应用到LR中，以及强调了Nuppy。应该只是为了后续的学习做一些准备。</p>
<p>一定一定要看这个作业<a target="_blank" rel="noopener" href="http://kakack.github.io/2017/09/Logistic-Regression-with-a-Neural-Network-mindset/">通过神经网络mindset实现简单的Logistic Regression</a></p>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%88%9D%E8%AF%86Learning-to-Rank/" rel="prev" title="机器学习算法-初识Learning to Rank">
      <i class="fa fa-chevron-left"></i> 机器学习算法-初识Learning to Rank
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/09/04/Java%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B04-%E6%B3%9B%E5%9E%8B%E6%95%B0%E7%BB%84%E5%88%97%E8%A1%A8/" rel="next" title="Java学习笔记4-泛型数组列表(ArrayList)">
      Java学习笔记4-泛型数组列表(ArrayList) <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lr%E7%9A%84%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D"><span class="nav-number">1.</span> <span class="nav-text">LR的梯度下降</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96"><span class="nav-number">2.</span> <span class="nav-text">向量化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8C%96%E7%9A%84lr"><span class="nav-number">3.</span> <span class="nav-text">向量化的LR</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">jiayi797</p>
  <div class="site-description" itemprop="description">.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">150</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jiayi797</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
    <span class="post-count">| 博客共334.5k字</span>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
