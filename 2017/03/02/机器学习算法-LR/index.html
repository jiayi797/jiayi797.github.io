<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
<!-- Referrer Policy调整致不蒜子单页面统计出错:https://senorui.top/posts/c33f.html -->
<meta name="referrer" content="no-referrer-when-downgrade">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"jiayi797.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="在说LR之前，我们先回顾一下logistic分布。 logistic分布 如果连续随机变量\(X\)服从logistic分布，则\(X\)具有下列分布函数和密度函数： \[ F(x)&#x3D;P(X&lt;&#x3D;x)&#x3D;\frac{1}{1+e^{-(x-u)&#x2F;r}} \] \[ f(x)&#x3D;F&#39;(x)&#x3D;\frac{e^{-(x-u)&#x2F;r}}{r(1+e^{-(x-u)&#x2F;r})^2} \]">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法-LR">
<meta property="og:url" content="http://jiayi797.github.io/about/2017/03/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-LR/index.html">
<meta property="og:site_name" content="甲乙小朋友的房子">
<meta property="og:description" content="在说LR之前，我们先回顾一下logistic分布。 logistic分布 如果连续随机变量\(X\)服从logistic分布，则\(X\)具有下列分布函数和密度函数： \[ F(x)&#x3D;P(X&lt;&#x3D;x)&#x3D;\frac{1}{1+e^{-(x-u)&#x2F;r}} \] \[ f(x)&#x3D;F&#39;(x)&#x3D;\frac{e^{-(x-u)&#x2F;r}}{r(1+e^{-(x-u)&#x2F;r})^2} \]">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-03-02-20-46-41.png">
<meta property="og:image" content="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-03-02-21-35-03.png">
<meta property="og:image" content="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-11-06-23-03-41.png">
<meta property="article:published_time" content="2017-03-02T14:45:32.000Z">
<meta property="article:modified_time" content="2018-12-17T07:42:01.000Z">
<meta property="article:author" content="jiayi797">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-03-02-20-46-41.png">

<link rel="canonical" href="http://jiayi797.github.io/about/2017/03/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-LR/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习算法-LR | 甲乙小朋友的房子</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">甲乙小朋友的房子</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">甲乙小朋友很笨，但甲乙小朋友不会放弃</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://jiayi797.github.io/about/2017/03/02/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-LR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="jiayi797">
      <meta itemprop="description" content=".">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="甲乙小朋友的房子">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习算法-LR
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2017-03-02 22:45:32" itemprop="dateCreated datePublished" datetime="2017-03-02T22:45:32+08:00">2017-03-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2018-12-17 15:42:01" itemprop="dateModified" datetime="2018-12-17T15:42:01+08:00">2018-12-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">机器学习算法</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>在说LR之前，我们先回顾一下logistic分布。</p>
<h1 id="logistic分布">logistic分布</h1>
<p>如果连续随机变量<span class="math inline">\(X\)</span>服从logistic分布，则<span class="math inline">\(X\)</span>具有下列<strong>分布函数和密度函数</strong>：</p>
<p><span class="math display">\[
F(x)=P(X&lt;=x)=\frac{1}{1+e^{-(x-u)/r}}
\]</span></p>
<p><span class="math display">\[
f(x)=F&#39;(x)=\frac{e^{-(x-u)/r}}{r(1+e^{-(x-u)/r})^2}
\]</span></p>
<p>其中</p>
<p><span class="math inline">\(u\)</span>为位置参数</p>
<p><span class="math inline">\(r&gt;0\)</span>为形状参数</p>
<p>其中，密度函数与分布函数的形状如图所示 <img src="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-03-02-20-46-41.png" /></p>
<p><strong>备注：分布密度函数与分布函数</strong></p>
<p>概率密度函数<span class="math inline">\(f(x)\)</span>：表示瞬时值落在某区间的概率，是幅值的概率。++用来描述连续型随机变量取值的密集程度的。++<span class="math inline">\(f(x)\)</span>表示X=x的概率是<span class="math inline">\(\int_0^1f(x)\)</span>。</p>
<p><span class="math inline">\(P(X=x|x \in (0,1))=\int_0^1f(x)\)</span></p>
<p>分布函数<span class="math inline">\(F(x)\)</span>：描述随机变量落在任一区间的概率。</p>
<p><span class="math inline">\(F(x)=P(X&lt;=x)\)</span></p>
<p>关系：</p>
<p>分布函数<span class="math inline">\(F(x)\)</span>是概率密度函数<span class="math inline">\(f(x)\)</span>从负无穷到正无穷上的积分；</p>
<p>在坐标轴上，概率密度函数的函数值y表示落在x点上的概率为y；分布函数的函数值y则表示x落在区间(-∞上的概率。</p>
<h1 id="二项logistic回归模型">二项logistic回归模型</h1>
<p><strong>用途：估计某个值的为哪一类的概率</strong></p>
<p>logistic回归是分类问题。前面我们讲的分类问题的输出都是 “yes”或者“no”。但是在现实生活中，我们并不是总是希望结果那么肯定，而是概率（发生的可能性）。比如，我们希望知道这个房子在第三个星期被卖出去的概率。那么以前的分类算法就无法使用了，这时logistic 回归就派上了用场。</p>
<p><strong>定义</strong></p>
<p>二项logistic回归模型是如下的条件概率分布：</p>
<p><span class="math display">\[
P(Y=1|x)=\frac{exp(wx+b)}{1+exp(wx+b)}
\]</span></p>
<p><span class="math display">\[
P(Y=0|x)=\frac{1}{1+exp(wx+b)}
\]</span></p>
<p>其中： <span class="math inline">\(x \in R^n\)</span> ：输入</p>
<p><span class="math inline">\(Y \in (0,1)\)</span> ：输出</p>
<p>给定<span class="math inline">\(x\)</span>，可以求得<span class="math inline">\(P(Y=1|x)\)</span>和<span class="math inline">\(P(Y=0|x)\)</span></p>
<p><strong>logistic回归模型的特点</strong></p>
<p>几率（odds）= 该事件发生的概率/该事件不该发生的概率，则对数几率：</p>
<p><span class="math display">\[
log(odds)=log(\frac{p}{1-p})=log(\frac{P(Y=1|x)}{1-P(Y=1|x)})=wx
\]</span></p>
<p>则：输出Y=1的对数几率=输入x的线性函数</p>
<h1 id="模型参数估计">模型参数估计</h1>
<p>输入： 一堆（x,y）</p>
<p>目标：估计参数w,b</p>
<p>方法：极大似然法</p>
<p><img src="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-03-02-21-35-03.png" /></p>
<h1 id="总结">总结</h1>
<ol type="1">
<li>逻辑回归是一种预测y的各类别的概率的模型，即计算P(Y=1|x)或者P(Y=0|x)</li>
<li>与机器学习过程类似，即 通过已知的大量（x,y），拟合计算参数w,b；再用y=wx+b来计算新的x下的y；把y输入sigmoid函数中，得到y为1的概率。</li>
</ol>
<h1 id="lr推导sigmoid损失函数梯度参数更新公式"><a target="_blank" rel="noopener" href="https://hyzhan.github.io/2017/05/23/2017-05-23-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92LR%E6%8E%A8%E5%AF%BC%EF%BC%88sigmoid%EF%BC%8C%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%8C%E6%A2%AF%E5%BA%A6%EF%BC%8C%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E5%85%AC%E5%BC%8F%EF%BC%89/">LR推导（sigmoid，损失函数，梯度，参数更新公式）</a></h1>
<p>这篇文章非常详细地介绍了逻辑回归的推导。非常有用。我在此处进行了转载。</p>
<h2 id="声明">声明</h2>
<ol type="1">
<li>$ x(1),x(2),...,x(m) $ 表示 n 维空间的一个样本，<span class="math inline">\(x(i)\)</span> 表示第i个样本，<span class="math inline">\(x(i)_j\)</span> 表示第i个样本的第j维的数据（因为<span class="math inline">\(x\)</span>是一个n维向量）。</li>
<li><span class="math inline">\(y(1),y(2),...,y(m)\)</span> 表示 k 维空间的一个观测结果，记k从1,2,...,k变化，即分类问题中的k个类别，也可以0为下标开始，不影响推导。</li>
<li><span class="math inline">\(\pi()\)</span>是我们学习到的概率函数，实现样本数据到预测结果的映射：<span class="math inline">\(R^n\rightarrow R^k\)</span>，（其实就是样本经过函数 <span class="math inline">\(\pi()\)</span>计算后得到各个类别的预测概率，即一个k维向量）， <span class="math inline">\(\pi(x)_u​\)</span>表示数据样本x属于类别u的概率，我们希望<span class="math inline">\(\pi()​\)</span>具有如下性质：</li>
</ol>
<blockquote>
<ol type="1">
<li><span class="math inline">\(\pi(x)_v&gt;0\)</span> (样本x属于类别v的概率大于0，显然概率必须大于0)</li>
<li><span class="math inline">\(\sum_{v=1}^k\pi(x)_v = 1\)</span>,样本x属于各个类别的概率和为1</li>
<li><span class="math inline">\(\pi(x(i))_{y(i)}在所有类别概率中最大\)</span></li>
</ol>
</blockquote>
<ol type="1">
<li><span class="math inline">\(A(u,v)\)</span>是一个指示函数，<span class="math inline">\(当u=v时A(u,v)=1，当u\neq v时A(u,v)=0，如A(u,y(i))\)</span>表示第i个观测结果是否为u</li>
</ol>
<h2 id="逻辑回归求解分类问题过程">逻辑回归求解分类问题过程</h2>
<p>对于二分类问题有k=2，对线性回归函数<span class="math inline">\(\lambda x\)</span>进行非线性映射得到：</p>
<p><span class="math display">\[ \pi(x)_1 = \frac{\rm e^{\lambda \cdot x}}{\rm e^{\lambda \cdot x}+1}\tag{1} \]</span> <span class="math display">\[ \pi(x)_2 = 1-\pi(x)_1= \frac{1}{\rm e^{\lambda \cdot x}+1}\tag{2} \]</span> 对于多分类问题有： <span class="math display">\[ \pi(x) = \frac{\rm e^{\lambda _v\cdot x}}{\sum_{u=1}^m\rm e^{\lambda_u \cdot x}}\tag{3} \]</span> 对<span class="math inline">\(\lambda\)</span>求偏导可得：</p>
<p><span class="math display">\[ \begin{aligned}
u = v 时，
\frac {\partial\,\pi (x)_v}{\lambda_{v,j}} &amp;= \frac{x_j\rm e^{\lambda _{v,j}\cdot x}\cdot \sum_{u=1}^m\rm e^{\lambda_{u,j} \cdot x}-x_j\rm e^{\lambda _{v,j}\cdot x}\rm e^{\lambda _{v,j}\cdot x}}{(\sum_{u=1}^m\rm e^{\lambda_{u,j} \cdot x})^2}\\
&amp; = \frac{x_j\rm e^{\lambda _{v,j}\cdot x}}{\sum_{u=1}^m\rm e^{\lambda_{u,j} \cdot x}} \cdot \frac{\sum_{u=1}^m\rm e^{\lambda_{u,j} \cdot x}-\rm e^{\lambda_{v,j}\cdot x}}{\sum_{u=1}^m\rm e^{\lambda_{u,j} \cdot x}}\\&amp; = x_j \pi(x)_v(1-\pi(x)_v)\end{aligned}\tag{4} \]</span></p>
<p><span class="math display">\[
\begin{aligned}
u \neq v 时
\frac {\partial\,\pi (x)_v}{\lambda_{u,j}}&amp;=-\frac{\rm e^{\lambda_{v,j} \cdot x} \cdot (x_j\rm e^{\lambda_{u,j} \cdot x})}{(\sum_{u=1}^m\rm e^{\lambda_{u,j} \cdot x})^2} \\
&amp;= -x_j \pi(x)_v\pi(x)_u, u\neq v时
\end{aligned}
\tag{5}
\]</span> 该分类问题的最大似然函数为： <span class="math display">\[ L(\lambda)=\prod_{i=1}^m \pi(x(i))_{y(i)}\tag{6} \]</span> 取对数得： <span class="math display">\[ f(\lambda)=\log L(\lambda)=\sum_{i=1}^m \log(\pi(x(i))_{y(i)})\tag{7} \]</span> 求似然函数最大值，令： <span class="math display">\[
\begin{aligned}
\frac{\partial\,f(\lambda)}{\partial \,\lambda_{u,j}} &amp;=\frac{\partial}{\partial \,\lambda_{u,j}}\sum_{i=1}^m \log(\pi(x(i))_{y(i)}) \\
&amp;= \sum_{i=1}^m \frac{1}{\pi(x(i))_{y(i)}}\frac{\partial}{\partial \,\lambda_{u,j}}\pi(x(i))_{y(i)} \\
&amp;= \sum_{\begin{array}{c}i=1,\\y(i)=u\end{array}}^m \frac{1}{\pi(x(i))_{y(i)}}\frac{\partial}{\partial \,\lambda_{u,j}}\pi(x(i))_{u} + \sum_{\begin{array}{c}i=1,\\y(i)\neq u\end{array}}^m \frac{1}{\pi(x(i))_{y(i)}}\frac{\partial}{\partial \,\lambda_{u,j}}\pi(x(i))_{y(i)}\\
&amp;= \sum_{\begin{array}{c}i=1,\\y(i)=u\end{array}}^m \frac{1}{\pi(x(i))_{y(i)}}x(i)_j\pi(x(i))_u(1-\pi(x(i))_u) \\
&amp;\quad - \sum_{\begin{array}{c}i=1,\\y(i)\neq u\end{array}}^m \frac{1}{\pi(x(i))_{y(i)}}x(i)_j\pi(x(i))_{y(i)} \pi(x(i))_u\\
&amp;= \sum_{\begin{array}{c}i=1,\\y(i)=u\end{array}}^m x(i)_j(1-\pi(x(i))_u)-\sum_{\begin{array}{c}i=1,\\y(i)\neq u\end{array}}^m x(i)_j \pi(x(i))_u \\
&amp;= \sum_{\begin{array}{c}i=1,\\y(i)=u\end{array}}^m x(i)_j - \sum_{i=1}^m x(i)_j\pi(x(i))_u \\
&amp;= 0
\end{aligned}
\tag{8}
\]</span> 得： <span class="math display">\[ \sum_{\begin{array}{c}i=1,\\y(i)=u\end{array}}^m x(i)_j = \sum_{i=1}^m x(i)_j\pi(x(i))_u\tag{9} \]</span> 代入<span class="math inline">\(A(u,y(i))=1\)</span>得： <span class="math display">\[ \sum_{i=1}^m x(i)_j\pi(x(i))_u = \sum_{i=1}^m x(i)_jA(u,y(i))\tag{10} \]</span> 综上有： <span class="math display">\[ \frac{\partial\,f(\lambda)}{\partial \,\lambda_{u,j}}=\sum_{i=1}^m x(i)_j(A(u,y(i))-\pi(x(i))_u)\tag{11} \]</span> 则参数更新公式为：</p>
<p><span class="math display">\[ \begin{aligned}\lambda_{u,j} &amp;= \lambda_{u,j} - \alpha \cdot \frac{\partial\,f(\lambda)}{\partial \,\lambda_{u,j}} \\&amp;= \lambda_{u,j} - \alpha \cdot \sum_{i=1}^m x(i)_j(A(u,y(i))-\pi(x(i))_u)\end{aligned}\tag{12} \]</span></p>
<h2 id="sigmoid函数的由来最大熵">sigmoid函数的由来（最大熵）</h2>
<p>由上文已知<span class="math inline">\(\pi()\)</span>具应有如下性质：</p>
<blockquote>
<ol type="1">
<li>样本x属于类别v的概率大于0，显然概率必须大于0<span class="math inline">\(\pi(x)_v&gt;0\tag{13}\)</span></li>
<li>样本x属于各个类别的概率和为1 <span class="math inline">\(\sum_{v=1}^k\pi(x)_v = 1\tag{14}\)</span></li>
<li><span class="math inline">\(\pi(x(i))_{y(i)}在所有类别概率中最大\)</span></li>
</ol>
</blockquote>
<p>其中对最后一个条件等价于尽可能的让<span class="math inline">\(\pi(x(i))\rightarrow y(i)\)</span> 即 <span class="math inline">\(\pi(x(i))\rightarrow A(u,y(i))\)</span>，理想情况为<span class="math inline">\(\pi(x(i))= A(u,y(i))\)</span>固有： <span class="math display">\[ \sum_{i=1}^m x(i)_j\pi(x(i))_u = \sum_{i=1}^m x(i)_jA(u,y(i))\tag{15}，对所有的u，j都成立 \]</span></p>
<p>对所有类别及所有样本取<span class="math inline">\(\pi()\)</span>的熵，得： <span class="math display">\[ f(v,i)=-\sum_{v=1}^k\sum_{i=1}^m\pi(x(i))_v \log(\pi(x(i))_v)\tag{16} \]</span> 得到一个优化问题：</p>
<p><img src="http://jiayi797.oss-cn-beijing.aliyuncs.com/2017-11-06-23-03-41.png" /></p>
<p><span class="math display">\[\left\{
\begin{aligned}
max f(v,i)=max (-\sum_{v=1}^k \sum_{i=1}^m pi(x(i))_v log(π(x(i))_v))\\
\pi(x)_v&gt;0\\
\sum_{v=1}^k π(x)_v = 1\\
\sum_{i=1}^m x(i)_j π(x(i))_u = \sum_{i=1}^m x(i)_j A(u,y(i))
\end{aligned}
\right.
\tag{17}\]</span> 利用拉格朗日对偶性求这个优化问题的对偶问题，首先引入拉格朗日函数：</p>
<p><span class="math display">\[ \begin{aligned}L &amp;= \sum_{j=1}^n\sum_{v=1}^k\lambda_{v,j} \left( \sum_{i=1}^m\pi(x(i))_vx(i)_j-A(v,y(i))x(i)_j \right)\\&amp;+ \sum_{v=1}^k\sum_{i=1}^m\beta_i(\pi(x(i))_v-1)\\&amp;- \sum_{v=1}^k\sum_{i=1}^m\pi(x(i))_v\log(\pi(x(i))_v)\end{aligned}\tag{18} \]</span> 其中 <span class="math display">\[ \beta&lt;0 \]</span> ,由KKT条件有： <span class="math display">\[ \frac{\partial\,L}{\partial \,\pi(x(i))_u} = \lambda_u\cdot x(i)+\beta_i-\log(\pi(x(i))_u) - 1 = 0  \quad对所有i,u \tag{19}\]</span></p>
<p><span class="math display">\[则：\pi(x(i))_u = e^{\lambda_u \cdot x(i)+\beta_i-1} \tag{20}\]</span></p>
<p>则： <span class="math display">\[\pi(x(i))_u = e^{\lambda_u \cdot x(i)+\beta_i-1} \tag{20}\]</span> 由（14）式得到： <span class="math display">\[  \sum_{v=1}^k e^{\lambda_u \cdot x(i)+\beta_i-1} = 1\\ \]</span> 即： <span class="math display">\[e^\beta=\frac{1}{\sum_{v=1}^ke^{\lambda_u \cdot x(i)-1}} \tag{21} \]</span> 代入（21）式消去常数项得： <span class="math display">\[ \pi(x(i))_u=\frac{e^{\lambda_u \cdot x}}{\sum_{v=1}^ke^{\lambda_u \cdot x}}\tag{22} \]</span> 即多分类问题对应的sigmoid函数</p>
<h1 id="其它文献">其它文献</h1>
<ol type="1">
<li><a target="_blank" rel="noopener" href="http://blog.csdn.net/cyh_24/article/details/50359055">Logistic Regression 的前世今生（理论篇）</a></li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2017/03/02/SQL-SQL%E6%B8%B8%E6%A0%87/" rel="prev" title="SQL游标">
      <i class="fa fa-chevron-left"></i> SQL游标
    </a></div>
      <div class="post-nav-item">
    <a href="/2017/03/03/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-SVM/" rel="next" title="机器学习算法-SVM">
      机器学习算法-SVM <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#logistic%E5%88%86%E5%B8%83"><span class="nav-number">1.</span> <span class="nav-text">logistic分布</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E9%A1%B9logistic%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="nav-number">2.</span> <span class="nav-text">二项logistic回归模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1"><span class="nav-number">3.</span> <span class="nav-text">模型参数估计</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">4.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lr%E6%8E%A8%E5%AF%BCsigmoid%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E6%A2%AF%E5%BA%A6%E5%8F%82%E6%95%B0%E6%9B%B4%E6%96%B0%E5%85%AC%E5%BC%8F"><span class="nav-number">5.</span> <span class="nav-text">LR推导（sigmoid，损失函数，梯度，参数更新公式）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A3%B0%E6%98%8E"><span class="nav-number">5.1.</span> <span class="nav-text">声明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%B1%82%E8%A7%A3%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E8%BF%87%E7%A8%8B"><span class="nav-number">5.2.</span> <span class="nav-text">逻辑回归求解分类问题过程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#sigmoid%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%B1%E6%9D%A5%E6%9C%80%E5%A4%A7%E7%86%B5"><span class="nav-number">5.3.</span> <span class="nav-text">sigmoid函数的由来（最大熵）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B6%E5%AE%83%E6%96%87%E7%8C%AE"><span class="nav-number">6.</span> <span class="nav-text">其它文献</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">jiayi797</p>
  <div class="site-description" itemprop="description">.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">150</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">34</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">32</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jiayi797</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
    <span class="post-count">| 博客共334.5k字</span>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
